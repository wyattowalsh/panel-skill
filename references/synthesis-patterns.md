# Synthesis Patterns Reference

This document provides patterns, algorithms, and templates for generating meaningful syntheses from expert panel discussions using Hegelian dialectic principles.

---

## Research Foundations

Synthesis mechanisms are critical to multi-agent discussion effectiveness:

- **Self-Consistency via Discussion (PanelGPT)**: Framing consensus as discussion rather than voting improves outcomesâ€”the discussion metaphor encourages reasoning, not just aggregation
- **Argument-Quality Weighting**: Research shows majority voting can entrench initial errors due to LLM conformity; weighting by reasoning quality counteracts this
- **Explicit Deliberation**: Requiring agents to explicitly agree/disagree and justify produces better syntheses than implicit aggregation
- **Context-Dependent Conclusions**: Research indicates forcing binary consensus reduces accuracy; acknowledging "it depends" with specific conditions is more accurate

---

## 1. Hegelian Dialectic Fundamentals

### Core Structure

**Thesis (Initial Position)**
- A claim, position, or proposed solution
- Grounded in specific reasoning and evidence
- Represents one valid perspective on the issue

**Antithesis (Opposition/Challenge)**
- A competing claim that challenges the thesis
- Not mere negation, but an alternative perspective
- Reveals limitations or blind spots in the thesis
- Also grounded in evidence and reasoning

**Synthesis (Higher-Order Integration)**
- Preserves valid elements from both thesis and antithesis
- Transcends simple compromise or averaging
- Generates NEW understanding not present in either original position
- Resolves contradictions at a higher level of abstraction
- May reveal that both positions are context-dependent

### Key Principles

1. **Aufhebung (Sublation)**: Each synthesis both cancels AND preserves elements of thesis/antithesis
2. **Emergence**: Synthesis contains insights that neither position held individually
3. **Context Sensitivity**: Recognition that different contexts may favor different positions
4. **Progressive Refinement**: Each round's synthesis becomes next round's thesis

### Anti-Patterns to Avoid

- **False Balance**: "Both sides have good points" without integration
- **Premature Consensus**: Glossing over real disagreements
- **Abstract Handwaving**: Vague synthesis that lacks actionable content
- **False Dichotomy**: Presenting issues as binary when they're multidimensional
- **Wishy-Washy Hedging**: "It depends" without specifying what it depends on

---

## 2. Per-Round Synthesis Format

### Standard Template

```markdown
ðŸ“‹ Round N Synthesis:

**Agreements:**
â€¢ [Explicit agreement with same reasoning]
â€¢ [Implicit agreement with different paths to same conclusion]

**Productive Tensions:**
â€¢ [Key disagreement #1 with specific nature of divergence]
â€¢ [Key disagreement #2 with underlying assumption causing split]

**Open Questions:**
â€¢ [Unresolved empirical question requiring evidence]
â€¢ [Definitional ambiguity requiring clarification]
â€¢ [Value-based tension requiring stakeholder input]

**Emerging Insights:**
â€¢ [Novel understanding that emerged from the exchange]
â€¢ [Reframing that clarifies the true nature of the problem]
â€¢ [Hidden assumption now made explicit]
```

### Rich Template (For Complex Discussions)

```markdown
ðŸ“‹ Round N Synthesis:

**Strong Consensus:**
â€¢ [Point of unanimous agreement]
  - Expert A's reasoning: [brief]
  - Expert B's reasoning: [brief]
  - Why this matters: [implication]

**Convergent Insights (Different Paths, Same Destination):**
â€¢ [Shared conclusion]
  - Via expertise domain 1: [reasoning]
  - Via expertise domain 2: [different reasoning]
  - Synthesis: [why both paths validate the conclusion]

**Productive Tensions:**
â€¢ [Specific disagreement]
  - Position A: [claim + reasoning]
  - Position B: [competing claim + reasoning]
  - Nature of disagreement: [factual/values/definitional]
  - Context sensitivity: [conditions favoring each position]

**Reframed Questions:**
â€¢ Original question: [initial framing]
â€¢ Better question: [reframing that emerged from discussion]
â€¢ Why this reframe matters: [what it reveals]

**Actionable Next Steps:**
â€¢ [Concrete investigation to resolve empirical question]
â€¢ [Specific stakeholder to consult for values question]
â€¢ [Targeted research to test competing hypothesis]
```

---

## 3. Synthesis Generation Algorithm

### Step 1: Extract Positions

```
For each expert response:
1. Identify main claims (thesis)
2. Note supporting evidence/reasoning
3. Extract caveats and boundary conditions
4. Capture confidence levels (explicit or implicit)
5. Note any questions raised
```

### Step 2: Map Agreement Space

**Explicit Agreement:**
- Same conclusion AND same reasoning
- Tag: `[STRONG_CONSENSUS]`

**Implicit Agreement:**
- Same conclusion BUT different reasoning paths
- Tag: `[CONVERGENT]`
- Action: Synthesize to show how different domains validate same point

**Partial Agreement:**
- Agreement on subset of claims
- Tag: `[PARTIAL]`
- Action: Clearly separate agreed vs. contested elements

### Step 3: Categorize Disagreements

**Factual Disagreements:**
- Different empirical claims
- Different predictions
- Tag: `[EMPIRICAL]`
- Resolution path: Identify evidence that would settle the dispute

**Values-Based Disagreements:**
- Different optimization criteria
- Different stakeholder priorities
- Tag: `[VALUES]`
- Resolution path: Make trade-offs explicit, identify decision-makers

**Definitional Disagreements:**
- Different meanings for key terms
- Different problem framings
- Tag: `[DEFINITIONAL]`
- Resolution path: Standardize definitions or acknowledge multiple valid framings

**Methodological Disagreements:**
- Different approaches to solving same problem
- Tag: `[METHODOLOGICAL]`
- Resolution path: Identify contexts where each approach excels

**Scope Disagreements:**
- Different boundaries for the problem
- Tag: `[SCOPE]`
- Resolution path: Explicitly define scope or address multiple scopes

### Step 4: Extract Emergent Insights

Look for:
- **Hidden assumptions made explicit**: "Both positions assume X, which may not hold if..."
- **Reframings**: "This isn't really about A vs. B, it's about optimizing for C vs. D"
- **Novel synthesis**: "Combining Expert A's insight with Expert B's constraint suggests..."
- **Meta-insights**: "Our disagreement reveals that we're solving different problems"
- **Contextual boundaries**: "Position A holds in context X, Position B holds in context Y"

### Step 5: Formulate Open Questions

Good open questions:
- Point to specific unknowns
- Suggest concrete resolution paths
- Are necessary for making progress
- Cannot be answered with current information

Template:
```
"To resolve [tension], we need to determine [specific unknown].
This could be answered by [concrete action/research/consultation]."
```

### Step 6: Generate Synthesis Statement

**For Consensus:**
```
"All experts agree that [conclusion] because [synthesized reasoning].
This is significant because [implication for the original question]."
```

**For Majority View:**
```
"Experts A and B argue [position] based on [reasoning],
while Expert C contends [alternative] based on [different reasoning].
The majority view is more persuasive in this case because [justification],
though Expert C's caveat about [concern] remains valid."
```

**For Unresolved Tension:**
```
"This panel reveals a fundamental trade-off between [value A] and [value B].
In contexts prioritizing [A], approach X is superior because [reasoning].
In contexts prioritizing [B], approach Y is superior because [reasoning].
Organizations should choose based on [specific decision criteria]."
```

---

## 4. Final Consensus Generation

### Consensus Labeling

Use precise labels:

**UNANIMOUS CONSENSUS:**
- All experts agree on conclusion and reasoning
- High confidence in actionability
- Format: "All N experts agree..."

**STRONG CONSENSUS:**
- All experts agree on conclusion
- Different reasoning paths converge
- Format: "Unanimous conclusion via multiple reasoning paths..."

**MAJORITY VIEW:**
- Most experts agree (e.g., 3 of 4)
- Minority view acknowledged
- Format: "The majority position (N of M experts) is... However, Expert X notes..."

**CONTESTED:**
- Fundamental disagreement remains
- May be irreducible due to values/context
- Format: "Experts are split between Position A and Position B, reflecting a genuine trade-off..."

**CONTEXT-DEPENDENT:**
- Different answers for different contexts
- Not a failure to reach consensus, but recognition of complexity
- Format: "The optimal approach depends on [specific factors]..."

### Weighted Summary Template

```markdown
## Final Synthesis

**Question:** [Original question clearly restated]

**Consensus Level:** [LABEL from above]

**Core Conclusion:**
[1-2 sentence answer that directly addresses the question]

**Supporting Analysis:**

From [Expertise Domain A]:
â€¢ [Key insight specific to this domain]
â€¢ [Reasoning and evidence]

From [Expertise Domain B]:
â€¢ [Key insight specific to this domain]
â€¢ [How it complements or tensions with Domain A]

**Integrated Perspective:**
[2-3 paragraphs synthesizing the above into coherent answer]

**Actionable Recommendations:**
1. [Concrete action item with reasoning]
2. [Concrete action item with conditions]
3. [Concrete action item with success criteria]

**Key Caveats:**
â€¢ [Boundary condition that would change the recommendation]
â€¢ [Assumption that, if false, would invalidate conclusion]

**Unresolved Questions:**
â€¢ [What we still don't know]
â€¢ [How to find out]

**Confidence Assessment:**
â€¢ High confidence in: [specific aspects]
â€¢ Moderate confidence in: [specific aspects]
â€¢ Low confidence in: [specific aspects]
â€¢ Requires further research: [specific aspects]
```

### Expertise-Weighted Synthesis

When expert relevance varies by topic:

```markdown
**On [Specific Sub-Question A]:**
Primary expertise: [Expert X's domain]
Conclusion: [Answer weighted toward Expert X's view]
Supporting view: [How other experts' perspectives complement this]

**On [Specific Sub-Question B]:**
Primary expertise: [Expert Y's domain]
Conclusion: [Answer weighted toward Expert Y's view]
Conflict note: [If Expert X disagrees, explain why Y's expertise dominates here]
```

---

## 5. Handling Unresolved Tensions

### When to Agree to Disagree

Legitimate reasons for persistent disagreement:

1. **Genuine Trade-offs**: Not every problem has one right answer
2. **Different Stakeholders**: Different constituencies have different needs
3. **Uncertainty**: Insufficient evidence to resolve empirical question
4. **Values Pluralism**: Multiple valid ethical frameworks

**Template:**
```markdown
**Unresolved Tension: [Topic]**

This panel reveals a genuine [trade-off/values conflict/empirical uncertainty].

Position A: [summary]
- Optimizes for: [value/goal]
- Strongest in context: [conditions]
- Risk if chosen: [downside]

Position B: [summary]
- Optimizes for: [different value/goal]
- Strongest in context: [different conditions]
- Risk if chosen: [downside]

**Decision Framework:**
Choose Position A if your context includes: [specific criteria]
Choose Position B if your context includes: [specific criteria]

**Red Flags:**
Avoid Position A if: [warning sign]
Avoid Position B if: [warning sign]
```

### Constructive "It Depends" Conclusions

Bad: "It depends on your situation."
Good: "The optimal approach depends on three specific factors:"

**Template:**
```markdown
**Context-Dependent Recommendation**

The answer to [question] depends on:

**Factor 1: [Specific, measurable attribute]**
â€¢ If [condition A]: Choose approach X because [reasoning]
â€¢ If [condition B]: Choose approach Y because [reasoning]

**Factor 2: [Specific, measurable attribute]**
â€¢ If [condition C]: This reinforces X because [reasoning]
â€¢ If [condition D]: This reinforces Y because [reasoning]

**Decision Matrix:**
| Factor 1 | Factor 2 | Recommendation | Confidence |
|----------|----------|----------------|------------|
| A        | C        | Strong X       | High       |
| A        | D        | Lean X         | Medium     |
| B        | C        | Lean Y         | Medium     |
| B        | D        | Strong Y       | High       |

**How to Determine Your Context:**
1. [Specific diagnostic question for Factor 1]
2. [Specific diagnostic question for Factor 2]
```

### Framing Trade-offs (Not False Dichotomies)

**Trade-off Template:**
```markdown
**Trade-off: [Value A] vs. [Value B]**

This is not a choice between right and wrong, but between two legitimate goals.

**Maximizing [Value A]:**
- Approach: [how to do this]
- Gains: [what you get]
- Costs: [what you sacrifice from Value B]
- Best for: [organizational context]

**Maximizing [Value B]:**
- Approach: [how to do this]
- Gains: [what you get]
- Costs: [what you sacrifice from Value A]
- Best for: [different organizational context]

**Balanced Approach:**
- [How to get 80% of both, if possible]
- [Or explain why this trade-off is zero-sum]

**Warning:** [Explain why trying to fully optimize both simultaneously will fail]
```

---

## 6. Templates for Synthesis Statements

### Agreement Templates

**Strong Consensus:**
```
"All experts converge on [conclusion]. [Expert A] reaches this through [domain A reasoning], while [Expert B] arrives via [domain B reasoning]. This convergence across methodologies strengthens confidence in [conclusion]."
```

**Qualified Agreement:**
```
"Experts agree on [core principle] but differ on [implementation details]. The consensus is that [general approach] is sound, with the caveat that [important boundary condition]."
```

### Disagreement Templates

**Productive Tension:**
```
"Expert A argues [position] based on [reasoning], while Expert B contends [alternative] based on [different reasoning]. Rather than a contradiction, this reveals [deeper insight about the problem space]."
```

**Irreducible Conflict:**
```
"This panel exposes a fundamental tension between [framework A] and [framework B]. Organizations must choose based on whether they prioritize [criterion from A] or [criterion from B]."
```

### Synthesis Templates

**Integrative Synthesis:**
```
"Combining Expert A's insight that [X] with Expert B's observation that [Y] suggests a synthesis: [Z]. This approach preserves the strengths of both positions while avoiding their respective weaknesses."
```

**Contextual Synthesis:**
```
"The apparent disagreement between Expert A and Expert B resolves when we recognize they're addressing different contexts. In [context 1], Expert A's approach of [X] is optimal because [reason]. In [context 2], Expert B's approach of [Y] is optimal because [different reason]."
```

**Sequential Synthesis:**
```
"Experts A and B aren't contradicting each other but describing sequential stages. Expert A's recommendation applies during [phase/condition 1], while Expert B's recommendation becomes relevant at [phase/condition 2]."
```

### Insight Emergence Templates

**Hidden Assumption Revealed:**
```
"The expert dialogue reveals a critical assumption: [assumption]. Both positions assume [X], but if [X] doesn't hold, then [implication for recommendations]."
```

**Reframing:**
```
"Initially framed as '[original question],' the expert discussion reveals the real question is '[better framing].' This reframe matters because [why this changes the answer]."
```

**Novel Integration:**
```
"Neither expert proposed [approach Z] individually, but Expert A's point about [X] combined with Expert B's point about [Y] suggests [Z] as a superior synthesis that [benefits]."
```

---

## 7. Examples: Raw Discussion â†’ Synthesis

### Example 1: Software Architecture Decision

**Raw Discussion:**

**Expert A (Security Specialist):**
"Use a monolithic architecture. Microservices multiply your attack surface and make it harder to maintain consistent security policies. Each service is a potential breach point."

**Expert B (Scalability Engineer):**
"Microservices are essential for scale. Monoliths become bottlenecks and single points of failure. You need independent scaling of components."

**Expert C (Cost Optimizer):**
"Start with a well-structured monolith. Microservices have significant operational overheadâ€”orchestration, monitoring, service mesh. Only justify the cost when monolith constraints actually manifest."

**Synthesis:**

```markdown
ðŸ“‹ Round 1 Synthesis:

**Agreements:**
â€¢ All experts agree that architecture should match organizational capabilities and actual requirements, not theoretical preferences
â€¢ Unanimous that premature architectural complexity is harmful

**Productive Tensions:**
â€¢ Security vs. Scalability: Expert A prioritizes attack surface minimization (favoring monolith), Expert B prioritizes independent scaling (favoring microservices)
â€¢ Timing disagreement: When to make the transition (if ever)

**Open Questions:**
â€¢ What is the specific scale threshold that justifies microservices complexity in this domain?
â€¢ What security controls make microservices acceptable from Expert A's perspective?

**Emerging Insights:**
â€¢ The disagreement is less "monolith vs. microservices" and more about WHEN and WHETHER transition is justified
â€¢ Expert C's "well-structured monolith" bridges the gapâ€”modularity can be achieved within monolith, enabling later extraction if needed
â€¢ Security and scalability aren't inherently opposed; they're optimization criteria with different architectural implications

**Follow-up for Round 2:**
â€¢ Expert A: What specific security controls would make microservices acceptable?
â€¢ Expert B: At what user/transaction volume do monolith bottlenecks become real rather than theoretical?
â€¢ Expert C: Can you outline a "modular monolith" approach that preserves migration optionality?
```

**Final Consensus (After Round 2):**

```markdown
## Final Synthesis: Architecture Decision

**Consensus Level:** STRONG CONSENSUS (with implementation variations)

**Core Conclusion:**
Start with a modular monolith and transition to microservices only when specific, measurable constraints appear, not based on anticipated scale.

**Integrated Perspective:**

All experts converged on a "modular monolith first" approach after Round 2 dialogue. The architecture should feature:

1. **Clear internal boundaries** (Expert C's contribution): Structure the monolith as independently deployable modules from day one
2. **Security-first design** (Expert A's contribution): Implement security controls that work in both monolith and microservices contextsâ€”zero trust networking, service-to-service authentication
3. **Observability infrastructure** (Expert B's contribution): Instrument for performance bottleneck detection so you know WHEN to split

**Transition Triggers** (Consensus from Round 2):

Migrate to microservices when you observe:
- Specific service scaling independently of others (measured via resource utilization)
- Teams blocked waiting for other teams' code freezes/releases (measured via deployment frequency)
- Monolith deployment time exceeding 30 minutes despite optimization
- Database connection pool exhaustion despite vertical scaling

**Actionable Recommendations:**

1. **Immediate:** Structure monolith with clear module boundaries, separate databases per domain
2. **Month 1-3:** Implement observability to detect transition triggers
3. **Ongoing:** Review metrics quarterly against transition triggers
4. **If triggers fire:** Extract highest-value service first (usually the scaling bottleneck)

**Key Caveats:**
â€¢ Assumes team size < 50 developers; larger teams may justify microservices earlier
â€¢ Assumes brownfield migration cost is acceptable; greenfield with distributed team might start distributed
â€¢ Requires discipline to maintain module boundaries in monolith

**Confidence Assessment:**
â€¢ High confidence: Modular monolith is correct starting point for most teams
â€¢ High confidence: Listed triggers are valid transition signals
â€¢ Moderate confidence: Specific numeric thresholds (30 min deploy, etc.) are context-dependent
â€¢ Requires case-by-case: Exact timeline for transition
```

---

### Example 2: Ethical Dilemma (Values-Based Disagreement)

**Raw Discussion:**

**Expert A (Privacy Advocate):**
"Absolutely do not implement user tracking. Privacy is a fundamental right. The fact that competitors do it doesn't make it ethical. Use privacy-preserving analytics methods."

**Expert B (Business Strategist):**
"Without understanding user behavior, you can't optimize the product. Users benefit from personalization. The question isn't whether to track, but how to do it transparently with informed consent."

**Synthesis:**

```markdown
ðŸ“‹ Round 1 Synthesis:

**Agreements:**
â€¢ Both experts agree transparency is essential (Expert A: as part of minimization; Expert B: as part of consent)
â€¢ Both agree "what competitors do" is not an ethical justification

**Productive Tensions:**
â€¢ Fundamental values conflict: Expert A prioritizes privacy as non-negotiable right; Expert B sees it as one value among others (including user experience)
â€¢ Different definitions of "harm": Expert A sees tracking itself as harm; Expert B sees only non-consensual or opaque tracking as harmful

**Open Questions:**
â€¢ Are there privacy-preserving analytics methods that satisfy both experts?
â€¢ What level of granularity in consent satisfies Expert A's concerns?

**Emerging Insights:**
â€¢ This is a genuine values conflict, not resolvable through technical means alone
â€¢ The answer may depend on: (a) legal jurisdiction, (b) user demographics, (c) sensitivity of domain
â€¢ Both experts might accept differential privacy or federated learning approaches

**Reframed Question:**
Original: "Should we implement user tracking?"
Better: "What analytics are essential for product improvement, and what's the minimum viable data collection to achieve that?"

**Follow-up for Round 2:**
â€¢ Expert A: What analytics approaches would you find acceptable?
â€¢ Expert B: What's the minimum data needed for your optimization goals?
â€¢ Both: Can differential privacy or on-device processing satisfy both criteria?
```

**Final Consensus:**

```markdown
## Final Synthesis: User Analytics Decision

**Consensus Level:** CONTEXT-DEPENDENT (irreducible values tension)

**Core Conclusion:**
The panel reveals a legitimate trade-off between privacy and personalization. Organizations must choose based on their domain, legal context, and user expectations.

**Supporting Analysis:**

From Privacy Perspective (Expert A):
â€¢ Tracking carries inherent risks: data breaches, de-anonymization, surveillance capitalism
â€¢ Users cannot meaningfully consent to complex data processing
â€¢ Privacy-preserving alternatives exist and should be default

From Business Perspective (Expert B):
â€¢ Product improvement requires understanding user behavior
â€¢ Transparent, consensual tracking can benefit users through personalization
â€¢ Absolute privacy prohibition may harm competitiveness and user experience

**Integrated Framework:**

Both experts agreed in Round 2 on this decision framework:

**Tier 1 (Always Acceptable):**
- Aggregated, anonymous analytics (no user identifiers)
- On-device analytics that never leave user's system
- Differential privacy with strong epsilon guarantees (Îµ < 1)

**Tier 2 (Acceptable with Strong Safeguards):**
- Pseudonymized analytics with informed, granular consent
- Minimal data collection (only what's necessary for stated purpose)
- User-accessible data deletion and export
- External privacy audits

**Tier 3 (Unacceptable to Expert A, Acceptable to Expert B):**
- Cross-site tracking
- Selling user data to third parties
- Opaque data practices

**Decision Criteria:**

**Choose Tier 1 if:**
- You're in healthcare, finance, or other sensitive domains
- Your users are privacy-conscious (measured via surveys)
- You're subject to GDPR, CCPA, or similar regulations with strict interpretation

**Choose Tier 2 if:**
- You need personalization for core product value
- You have resources for robust consent management
- Your domain is competitive and users expect personalization

**Avoid Tier 3:**
- Both experts agree these practices are ethically questionable
- Legal risk is high and increasing

**Key Insight:**
The experts' disagreement isn't about facts but about whether privacy is a trumping value or one value among others. Your organization's position on this philosophical question should guide the decision.

**Unresolved Tension:**
Expert A maintains that even "consensual" tracking in Tier 2 is problematic due to power imbalances and dark patterns. Expert B maintains that blanket prohibition in Tier 1 paternalistically denies users the choice to trade privacy for features. This tension is irreducible.

**Actionable Recommendation:**
1. Start with Tier 1 approaches
2. Measure whether Tier 1 analytics provide sufficient insight for product decisions
3. Only implement Tier 2 if you can demonstrate Tier 1 is insufficient AND you have resources for robust safeguards
4. Submit Tier 2 implementation to external privacy audit before deployment
```

---

## 8. Quality Checklist for Syntheses

Before finalizing a synthesis, verify:

- [ ] **Actionable**: Does it provide specific next steps, not just observations?
- [ ] **Preserves Nuance**: Are important caveats and boundary conditions included?
- [ ] **Not Wishy-Washy**: If it says "it depends," does it specify on what and how to decide?
- [ ] **Acknowledges Uncertainty**: Are confidence levels appropriate?
- [ ] **Shows Emergence**: Does it contain insights not present in individual expert statements?
- [ ] **Respects Expertise**: Are domain-specific insights weighted appropriately?
- [ ] **Identifies Open Questions**: Are unresolved issues clearly stated with resolution paths?
- [ ] **Avoids False Balance**: If experts genuinely disagree, is that acknowledged rather than papered over?
- [ ] **Contextually Grounded**: Are recommendations tied to specific conditions/contexts?
- [ ] **Directly Answers Question**: Does the synthesis actually address what was asked?

---

## 9. Anti-Patterns and Failure Modes

### Synthesis Red Flags

**Red Flag: Vague Integration**
```
âŒ BAD: "Both experts make valid points. The truth is somewhere in between."
âœ… GOOD: "Expert A's point holds in [context X] while Expert B's point holds in [context Y].
          Specifically: when [measurable condition], choose A; when [different condition], choose B."
```

**Red Flag: Ignoring Disagreement**
```
âŒ BAD: "Experts agree on the general approach." [when they actually fundamentally disagree]
âœ… GOOD: "Experts agree on [specific point] but fundamentally disagree on [specific other point].
          This disagreement stems from [values/factual/definitional difference]."
```

**Red Flag: Premature Consensus**
```
âŒ BAD: "After one round, the panel reaches consensus that [complex question] should be handled by [simple answer]."
âœ… GOOD: "Round 1 identifies key tensions: [list]. Round 2 explores [specific tension].
          Consensus emerges after [specific insight] resolves the apparent contradiction."
```

**Red Flag: Abstraction Without Grounding**
```
âŒ BAD: "The synthesis is to adopt a holistic, integrated approach that balances all stakeholder needs."
âœ… GOOD: "Stakeholder A needs [specific thing], stakeholder B needs [different thing].
          Satisfy A by [concrete action], satisfy B by [different concrete action].
          Where they conflict (e.g., on [specific issue]), prioritize A if [condition], B if [other condition]."
```

**Red Flag: Expertise Mismatch**
```
âŒ BAD: Treating all expert opinions equally when question clearly falls in one expert's domain
âœ… GOOD: "On this [domain-specific question], Expert X's perspective is most relevant because [reasoning].
          Expert Y's perspective, while valuable for [different aspect], is less applicable here because [reasoning]."
```

---

## 10. Meta-Synthesis: When the Process Itself Provides Insight

Sometimes the PROCESS of attempting synthesis reveals something important:

**Pattern: Persistent Disagreement â†’ Values Discovery**
```markdown
"The panel's inability to reach consensus on [question] is itself informative.
It reveals that [question] is not a technical question but a values question.
The disagreement reflects legitimate differences in [value A vs. value B]."
```

**Pattern: Easy Consensus â†’ Deeper Questions**
```markdown
"The panel quickly agreed on [answer], which suggests this is well-understood territory.
However, this easy consensus raises a more interesting question: [deeper question that experts hadn't considered]."
```

**Pattern: Confusion â†’ Ambiguity Discovery**
```markdown
"Experts initially talked past each other because [term X] means [definition A] in Expert A's domain
but [definition B] in Expert B's domain. Disambiguating this term reveals we're actually asking two
separate questions: [question 1] and [question 2]."
```

**Pattern: Expertise Gaps**
```markdown
"All experts acknowledged this question requires input from [missing expertise domain].
The panel can address [subset of question] but [other aspect] requires [specific additional expert]."
```

---

## Conclusion

Effective synthesis is an active, creative process, not passive summarization. It requires:

1. **Precise categorization** of agreements, disagreements, and their natures
2. **Emergence detection** to find insights beyond what any expert stated
3. **Context sensitivity** to recognize when different answers apply in different situations
4. **Intellectual honesty** to acknowledge genuine uncertainties and trade-offs
5. **Actionability** to provide specific guidance, not abstract observations

The Hegelian dialectic succeeds when synthesis genuinely transcends thesis and antithesisâ€”when the expert panel collectively reaches understanding that no individual expert possessed at the start.
